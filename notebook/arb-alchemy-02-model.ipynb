{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abuonomo/code/DataSquad/astro2020/venv/lib/python3.7/site-packages/_pytest/mark/structures.py:380: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "from gensim.corpora import MmCorpus, Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "from sqlalchemy import Column, Integer, String, ForeignKey, Boolean, Float\n",
    "from sqlalchemy import create_engine, func\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abuonomo/code/DataSquad/astro2020/venv/lib/python3.7/site-packages/nltk/decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "/Users/abuonomo/code/DataSquad/astro2020/venv/lib/python3.7/site-packages/nltk/lm/counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence, defaultdict\n",
      "/Users/abuonomo/code/DataSquad/astro2020/venv/lib/python3.7/site-packages/tqdm/std.py:651: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'db' from '../src/db.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp; imp.reload(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data_dir = Path(\"../scratch/prepared_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6869/6869 [00:02<00:00, 2923.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# corpus = MmCorpus('../scratch/prepared_data/corpus.mm')\n",
    "# dictionary = Dictionary.load(\"../scratch/prepared_data/dct.mm\")\n",
    "corpus, dictionary, corp2paper, dct2kwd = db.read_from_prepared_data(prepared_data_dir)\n",
    "mdir = Path('../scratch/tmodels/')\n",
    "n_topics = 20\n",
    "tmodel_loc = mdir / f'topic_model{n_topics}'\n",
    "\n",
    "lda_model = LdaModel.load(str(tmodel_loc))\n",
    "tm = db.TopicModeler(dictionary, corpus)\n",
    "embedding = tm.get_inference(lda_model)\n",
    "coh_per_topic = tm.get_coherence_model(lda_model).get_coherence_per_topic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from topic_modeling import NumPyEncoder, __num_dist_rows__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def __num_dist_rows__(array, ndigits=2):\n",
    "#     return array.shape[0] - int((pd.DataFrame(array).sum(axis=1) < 0.9).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6869"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis._prepare.__num_dist_rows__(np.matrix(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (pd.DataFrame(embedding).sum(axis=1) < 0.999).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyLDAvis.utils.NumPyEncoder = NumPyEncoder\n",
    "# pyLDAvis._prepare.__num_dist_rows__ = __num_dist_rows__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x13130e790>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imp.reload(pyLDAvis.gensim)\n",
    "# imp.reload(pyLDAvis)b\n",
    "lda_model.id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/abuonomo/code/DataSquad/astro2020/venv/lib/python3.7/site-packages/pyLDAvis/_prepare.py\u001b[0m(64)\u001b[0;36m_input_check\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     63 \u001b[0;31m    \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 64 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0m__num_dist_rows__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_term_dists\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mttds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     65 \u001b[0;31m        \u001b[0merr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not all rows (distributions) in topic_term_dists sum to 1.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "viz_data = pyLDAvis.gensim.prepare(lda_model, tm.corpus, lda_model.id2word, doc_topic_dist=np.matrix(embedding), sort_topics=False, mds=\"mmds\", start_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1630"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lda_model.id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1580"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tm.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_loc = '../scratch/test.sqlite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"sqlite:///{db_loc}\")\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7245"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.query(db.Paper.id).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp2paper_dct = {c: p for c, p in corp2paper}\n",
    "dct2kwd_dct = {d: k for d, k in dct2kwd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_inds, paper_inds = zip(*corp2paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper2bibcode = session.query(db.Paper.id, db.Paper.bibcode).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = (\n",
    "#     session.query(db.Paper.bibcode)\n",
    "#     .filter(db.Paper.id.in_([p for _, p in corp2paper]))\n",
    "# )\n",
    "# bibs = [q[0] for q in q.all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibs = [[c, paper2bibcode_dct[p]] for c, p in corp2paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibs = [paper2bibcode_dct[p] for c, p in corp2paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df = pd.DataFrame(embedding)\n",
    "embedding_df.index = paper_inds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Topic Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_min = 1997\n",
    "year_max = 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce56f7541229498ab9d2c71e678dfaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:00<00:00, 108.62it/s]A\n"
     ]
    }
   ],
   "source": [
    "all_time_series = []\n",
    "for topic in tqdm(embedding_df.columns):\n",
    "    ids_in_topic = embedding_df.index[embedding_df.loc[:, topic] > thresh].tolist() # function to include options with argmax as well?\n",
    "    years_query = (\n",
    "        session.query(db.Paper.year, func.count(db.Paper.year)) # Don't really need to add journal exlusions because already limiting to the IDs which are in topic model\n",
    "        .filter(db.Paper.id.in_(ids_in_topic))\n",
    "        .filter(db.Paper.year <= year_max)\n",
    "        .filter(db.Paper.year >= year_min)\n",
    "        .group_by(db.Paper.year)\n",
    "    )\n",
    "    year_counts = years_query.all()\n",
    "    ycd = defaultdict(int, {y:c for y, c in year_counts})\n",
    "    topic_time_series = [{\"topic\": topic, \"year\": y, \"count\": ycd[y]} for y in range(year_min, year_max)]\n",
    "    all_time_series = all_time_series + topic_time_series\n",
    "\n",
    "ts_df_long = pd.DataFrame(all_time_series)\n",
    "ts_df = ts_df_long.pivot(index='topic', columns=\"year\", values=\"count\")\n",
    "\n",
    "features_df = extract_features(ts_df_long, column_id='topic', column_sort='year')\n",
    "features_df['coherence_score'] = coh_per_topic\n",
    "\n",
    "def cagr(x_row):\n",
    "    x = x_row.values\n",
    "    nz_inds = np.nonzero(x)[0]\n",
    "    if len(nz_inds) == 0:  # If all are 0, set CAGR to 0\n",
    "        return 0\n",
    "    else:\n",
    "        first_nonzero_index = nz_inds[0]\n",
    "        x = x[first_nonzero_index:]  # Not valid if starts with 0. Becomes inf\n",
    "        x = x[~np.isnan(x)]  # For normalized time series, NaNs before any occurrence of kwd\n",
    "    if len(x) < 2:  # If no periods, set CAGR to 0\n",
    "        return 0\n",
    "    else:\n",
    "        ys = x_row.index\n",
    "        period = max(ys) - min(ys)\n",
    "        return (x[-1] / x[0]) ** (1 / period) - 1\n",
    "\n",
    "features_df['CAGR'] = ts_df.apply(cagr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dtw_time_analysis' from '../src/dtw_time_analysis.py'>"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dtw_time_analysis as dtw\n",
    "import imp; imp.reload(dtw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dtw_time_analysis:Computing dynamic time warping between keywords.\n",
      "INFO:dtw_time_analysis:window: 1.\n"
     ]
    }
   ],
   "source": [
    "dtw_df = dtw.dtw_kwds(ts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro202",
   "language": "python",
   "name": "astro2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
