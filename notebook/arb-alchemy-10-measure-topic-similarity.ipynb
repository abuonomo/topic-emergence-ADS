{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_word_array(m):\n",
    "    topic_word_scores = m0.show_topics(m0.num_topics, m0.num_terms, formatted=False)\n",
    "\n",
    "    topic_word_lisklearn []\n",
    "    for t, word_scores in topic_word_scores:\n",
    "        l = [(m0.id2word.token2id[w], p) for w, p in word_scores]\n",
    "        l = [v for _, v in sorted(l)]\n",
    "        topic_word_list.append(l)\n",
    "        \n",
    "    topic_word_matrix = np.stack(topic_word_list)\n",
    "    \n",
    "    return topic_word_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [2, 3, 4]\n",
    "# names = ['', '2', '3', '4'] # First example experiment from different keyword database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for n in names:\n",
    "    in_model = Path(f'../models/example_experiment{n}/topic_models/topic_model200')\n",
    "    m = LdaModel.load(str(in_model))\n",
    "    models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment='topic-model-embeddings')\n",
    "xl = []\n",
    "metas = []\n",
    "all_top_terms = []\n",
    "for i, m0 in enumerate(models):\n",
    "    x = get_topic_word_array(m0)\n",
    "    meta = np.repeat(i, x.shape[0])\n",
    "    top_terms = [s for _, s in m0.print_topics(num_topics=m0.num_topics)]\n",
    "    \n",
    "    xl.append(x)\n",
    "    metas.append(list(zip(meta, top_terms)))\n",
    "\n",
    "embedding = np.concatenate(xl)\n",
    "metadata = [m for tm in metas for m in tm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=x.shape[0], random_state=0).fit(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = [(m, t, k) for (m, t), k in zip(metadata, kmeans.labels_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_embedding(embedding, metadata=metadata, metadata_header=[\"topic_set\", \"terms\", \"kmeans_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.3.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topic-emergence-ADS",
   "language": "python",
   "name": "topic-emergence-ads"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
